# ğŸŒ Web Content Extraction API ğŸ“„

## ğŸ”¥ Votre passerelle vers l'extraction intelligente de contenu web ğŸ”¥

[![GitHub stars](https://img.shields.io/github/stars/simonpierreboucher0/web-content-api?style=social)](https://github.com/simonpierreboucher0/web-content-api/stargazers)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.105.0+-green.svg)](https://fastapi.tiangolo.com/)

---

## âœ¨ CaractÃ©ristiques principales

ğŸ“„ **Extraction puissante** - RÃ©cupÃ©rez le contenu brut et traitÃ© des pages web  
ğŸ§© **Normalisation des donnÃ©es** - Format standardisÃ© pour faciliter l'intÃ©gration  
âš¡ **Haute performance** - Mise en cache intelligente des rÃ©sultats  
ğŸ›¡ï¸ **Robustesse intÃ©grÃ©e** - Gestion avancÃ©e des erreurs et des timeouts  
ğŸ“Š **Logging dÃ©taillÃ©** - Suivi complet des opÃ©rations d'extraction  
ğŸŒ **Support multilingue** - Extraction du contenu en plusieurs langues  

---

## ğŸ¤– Moteur d'extraction pris en charge

### ğŸŸ¢ Tavily
Extraction prÃ©cise optimisÃ©e pour la rÃ©cupÃ©ration d'information structurÃ©e.

| FonctionnalitÃ© | Description | Avantage |
|----------------|-------------|----------|
| ğŸ” **Profondeur d'extraction** | Modes basic et advanced | FlexibilitÃ© selon les besoins |
| ğŸ“œ **Contenu brut** | Texte original de la page | DonnÃ©es non filtrÃ©es pour analyse personnalisÃ©e |
| ğŸ“Š **Contenu structurÃ©** | Texte nettoyÃ© et organisÃ© | Facilite le traitement ultÃ©rieur |
| ğŸ—ï¸ **Extraction de structure** | Organisation hiÃ©rarchique du contenu | ComprÃ©hension de l'architecture de la page |
| ğŸ–¼ï¸ **Images contextuelles** | Capture des images avec mÃ©tadonnÃ©es | Enrichissement visuel du contenu |
| ğŸ” **DÃ©tection de contenu dynamique** | Gestion du JavaScript et contenu chargÃ© dynamiquement | Extraction complÃ¨te mÃªme sur sites modernes |
| â±ï¸ **Optimisation des performances** | Extraction rapide et efficace | Traitement de grand volume d'URLs |
| ğŸ§© **CompatibilitÃ© multiformat** | Support de divers formats web | Large couverture de sites |

---

## ğŸ› ï¸ Installation facile en 3 Ã©tapes

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/simonpierreboucher0/WEB-EXTRACTION.git
cd WEB-EXTRACTION
```

### 2ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configurer votre clÃ© API
CrÃ©ez un fichier `.env` avec votre clÃ©:
```ini
TAVILY_KEY=votre_clÃ©_tavily
```

---

## ğŸš€ Guide d'utilisation rapide

### â–¶ï¸ DÃ©marrer le serveur
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8001
```

### ğŸŒ Documentation interactive
AccÃ©dez Ã  l'interface Swagger pour tester l'API:
```
http://localhost:8001/docs
```

### ğŸ“„ Extraction simple avec Tavily
```bash
curl -X 'POST' \
  'http://localhost:8001/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "urls": "https://en.wikipedia.org/wiki/Artificial_intelligence",
    "include_images": true,
    "extract_depth": "basic"
  }'
```

### ğŸ“š Extraction de plusieurs URLs
```bash
curl -X 'POST' \
  'http://localhost:8001/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "urls": [
      "https://en.wikipedia.org/wiki/Artificial_intelligence",
      "https://arxiv.org/abs/2307.06435"
    ],
    "include_images": true
  }'
```

---

## ğŸ“Š Structure complÃ¨te des requÃªtes

```json
{
  "urls": "https://example.com/page",            // ğŸ”— URL ou liste d'URLs (obligatoire)
  "include_images": true,                        // ğŸ–¼ï¸ Inclure les images
  "include_raw_content": false,                  // ğŸ“œ Inclure le contenu brut non traitÃ©
  "extract_depth": "advanced",                   // ğŸ” Profondeur d'extraction (basic, advanced)
  "include_links": true,                         // ğŸ”— Inclure les liens trouvÃ©s
  "max_tokens": 10000                            // ğŸ“ Limite de taille du texte extrait
}
```

---

## ğŸ“‹ Format des rÃ©sultats

```json
{
  "request_id": "550e8400-e29b-41d4-a716-446655440000", // ğŸ†” Identifiant unique de requÃªte
  "urls": ["https://example.com/page"],                // ğŸ”— URLs d'origine
  "results": [                                         // ğŸ“Š Liste des rÃ©sultats
    {
      "url": "https://example.com/page",               // ğŸ”— URL de la page
      "title": "Titre de la page web",                 // ğŸ“ Titre de la page
      "content": "Contenu principal extrait...",       // ğŸ“„ Contenu traitÃ©
      "raw_content": "HTML brut ou texte complet...",  // ğŸ“œ Contenu brut (si demandÃ©)
      "author": null,                                  // âœï¸ Auteur (si disponible)
      "published_date": null,                          // ğŸ“… Date de publication (si disponible)
      "images": [                                       // ğŸ–¼ï¸ Images extraites
        {
          "url": "https://example.com/image.jpg",      // ğŸ”— URL de l'image
          "alt_text": "Description de l'image",        // ğŸ“ Texte alternatif
          "width": 800,                                // ğŸ“ Largeur en pixels
          "height": 600                                // ğŸ“ Hauteur en pixels
        }
      ],
      "links": null                                    // ğŸ”— Liens extraits (si demandÃ©s)
    }
  ],
  "failed_urls": [],                                   // âŒ URLs qui ont Ã©chouÃ©
  "engine": "tavily",                                  // ğŸŒ Moteur utilisÃ©
  "time_taken": 0.35,                                  // â±ï¸ Temps d'exÃ©cution (secondes)
  "cached": false,                                     // ğŸ”„ RÃ©sultat depuis le cache?
  "status": "ok",                                      // âœ… Ã‰tat de la requÃªte
  "cost_info": {                                       // ğŸ’° Informations de coÃ»t
    "total_urls": 1,                                   // ğŸ”¢ Nombre total d'URLs
    "successful_extractions": 1,                       // âœ… Extractions rÃ©ussies
    "cached_results": 0,                               // ğŸ”„ RÃ©sultats depuis le cache
    "api_calls": 1                                     // ğŸ“ Nombre d'appels API effectuÃ©s
  }
}
```

---

## ğŸ’¡ Cas d'utilisation avancÃ©s

### ğŸ“‘ Extraction parallÃ¨le de plusieurs URLs

```python
import requests
import concurrent.futures

def batch_extract(urls):
    # DÃ©couper en lots de 5 URLs
    batches = [urls[i:i+5] for i in range(0, len(urls), 5)]
    all_results = []
    failed_urls = []
    
    def extract_batch(batch):
        try:
            response = requests.post(
                "http://localhost:8001/extract",
                json={
                    "urls": batch,
                    "include_images": True,
                    "extract_depth": "basic"
                },
                timeout=30
            )
            if response.status_code == 200:
                data = response.json()
                return data["results"], data["failed_urls"]
            return [], batch
        except Exception as e:
            print(f"Erreur batch: {str(e)}")
            return [], batch
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(extract_batch, batch) for batch in batches]
        
        for future in concurrent.futures.as_completed(futures):
            results, failures = future.result()
            all_results.extend(results)
            failed_urls.extend(failures)
    
    return all_results, failed_urls

# Liste d'URLs Ã  traiter
news_sites = [
    "https://www.reuters.com/technology/ai",
    "https://www.theverge.com/ai-artificial-intelligence",
    "https://www.wired.com/category/artificial-intelligence/",
    "https://venturebeat.com/category/ai/",
    "https://techcrunch.com/category/artificial-intelligence/",
    "https://www.technologyreview.com/topic/artificial-intelligence/",
    "https://www.zdnet.com/topic/artificial-intelligence/"
]

results, failures = batch_extract(news_sites)
print(f"Extractions rÃ©ussies: {len(results)}, Ã‰checs: {len(failures)}")
```

### ğŸ“° Extraction d'articles d'actualitÃ©

```python
import requests
import json
from datetime import datetime

def extract_news_article(url):
    response = requests.post(
        "http://localhost:8001/extract",
        json={
            "urls": url,
            "include_images": True
        }
    )
    
    if response.status_code != 200:
        return {"error": f"Extraction failed: {response.status_code}"}
    
    data = response.json()
    
    if not data["results"]:
        return {"error": "No content extracted"}
    
    article = data["results"][0]
    
    # Formater l'article
    formatted_article = {
        "title": article.get("title", "Untitled Article"),
        "url": article.get("url"),
        "content": article.get("content", "").strip(),
        "word_count": len(article.get("content", "").split()),
        "reading_time_minutes": round(len(article.get("content", "").split()) / 200),  # ~200 mots/minute
        "main_image": article.get("images", [{}])[0].get("url") if article.get("images") else None,
        "extraction_date": datetime.now().isoformat()
    }
    
    return formatted_article

# Exemple
news_url = "https://www.theverge.com/2024/1/15/24039104/openai-anthropic-meta-google-ai-regulation"
article = extract_news_article(news_url)
print(json.dumps(article, indent=2))
```

---

## ğŸ§ª Tests de santÃ© et surveillance

L'API intÃ¨gre un endpoint de santÃ© complet pour surveiller l'Ã©tat du service:

```bash
curl -X GET http://localhost:8001/health
```

Exemple de rÃ©ponse:
```json
{
  "status": "healthy",
  "time": "2024-08-07T14:35:22.451Z",
  "version": "1.0.0",
  "uptime": "2 days, 5:12:30",
  "memory_usage": "98452 KB",
  "hostname": "extraction-api-server",
  "cache_entries": 145,
  "api_statuses": {
    "tavily": "ok"
  },
  "response_time": "0.0823s"
}
```

---

## ğŸ”’ SÃ©curitÃ© et bonnes pratiques

- ğŸ”‘ **Gestion des clÃ©s**: StockÃ©es localement dans `.env`, jamais exposÃ©es
- ğŸ›¡ï¸ **Rate Limiting**: Protection contre les abus via limitation de taux
- ğŸ”’ **CORS configurable**: Protection contre les requÃªtes non autorisÃ©es
- ğŸ“ **Logging sÃ©curisÃ©**: Masquage automatique des informations sensibles
- â±ï¸ **Timeouts contrÃ´lÃ©s**: Ã‰vite les requÃªtes bloquantes
- ğŸ”„ **Retry avec backoff**: Gestion intelligente des erreurs temporaires
- ğŸ§¹ **Nettoyage des caches**: LibÃ©ration automatique des ressources

---

## ğŸ“š FonctionnalitÃ©s avancÃ©es

### ğŸ“‹ SystÃ¨me de mise en cache
Le systÃ¨me met intelligemment en cache les rÃ©sultats pour optimiser les performances:

```bash
# PremiÃ¨re requÃªte (non mise en cache)
curl -X 'POST' \
  'http://localhost:8001/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "urls": "https://en.wikipedia.org/wiki/Artificial_intelligence",
    "include_images": true
  }'
  
# RequÃªte identique (depuis le cache, beaucoup plus rapide)
curl -X 'POST' \
  'http://localhost:8001/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "urls": "https://en.wikipedia.org/wiki/Artificial_intelligence",
    "include_images": true
  }'
```

### ğŸ“„ Extraction avec diffÃ©rentes profondeurs
Adaptez la profondeur d'extraction selon vos besoins:

```bash
# Extraction basique (plus rapide)
curl -X 'POST' \
  'http://localhost:8001/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "urls": "https://example.com/article",
    "extract_depth": "basic"
  }'

# Extraction avancÃ©e (plus complÃ¨te)
curl -X 'POST' \
  'http://localhost:8001/extract' \
  -H 'Content-Type: application/json' \
  -d '{
    "urls": "https://example.com/article",
    "extract_depth": "advanced"
  }'
```

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues! Voici comment participer:

1. ğŸ´ **Fork** le dÃ©pÃ´t
2. ğŸ”„ CrÃ©ez une **branche** (`git checkout -b feature/ma-fonctionnalite`)
3. âœï¸ Faites vos **modifications**
4. ğŸ“¦ **Commit** vos changements (`git commit -m 'Ajout de ma fonctionnalitÃ©'`)
5. ğŸ“¤ **Push** vers la branche (`git push origin feature/ma-fonctionnalite`)
6. ğŸ” Ouvrez une **Pull Request**

### ğŸ’¼ IdÃ©es de contributions

- ğŸ”Œ Support de nouveaux moteurs d'extraction
- ğŸ§° Options d'extraction additionnelles
- ğŸ“Š Visualisation du contenu extrait
- ğŸŒ Interface utilisateur web simple
- ğŸ“ Expansion de la documentation
- ğŸ§ª Tests additionnels

---

## ğŸ“œ Licence

Ce projet est sous licence [MIT](LICENSE) - voir le fichier LICENSE pour plus de dÃ©tails.

---

## â“ FAQ

### ğŸš€ Comment optimiser les performances?
Activez la mise en cache, limitez l'extraction aux donnÃ©es nÃ©cessaires (dÃ©sactivez les images si non requises), et utilisez la profondeur d'extraction appropriÃ©e.

### ğŸŒ L'API fonctionne-t-elle sur tous les sites web?
La plupart des sites modernes sont supportÃ©s, mais certains peuvent avoir des protections anti-scraping ou des structures complexes qui rendent l'extraction difficile.

### âš™ï¸ Comment adapter l'API Ã  mes besoins spÃ©cifiques?
Le code source est conÃ§u pour Ãªtre facilement extensible - vous pouvez ajouter de nouveaux moteurs d'extraction ou personnaliser les paramÃ¨tres existants.

### ğŸ“± Puis-je intÃ©grer cette API dans des applications mobiles?
Oui, l'API peut Ãªtre appelÃ©e depuis n'importe quelle application capable d'effectuer des requÃªtes HTTP, y compris les applications mobiles.

### ğŸ” Quelles sont les limites d'extraction?
Les limites dÃ©pendent principalement du plan de l'API Tavily que vous utilisez. Consultez leur documentation pour plus de dÃ©tails sur les quotas et les limites.

---

## ğŸ‘¨â€ğŸ’» Auteurs

- ğŸš€ [Simon-Pierre Boucher](https://github.com/simonpierreboucher0) - CrÃ©ateur principal

---

<p align="center">
â­ N'oubliez pas de mettre une Ã©toile si ce projet vous a Ã©tÃ© utile! â­
</p>

<p align="center">
ğŸ”— <a href="https://github.com/simonpierreboucher0/WEB-EXTRACTION">GitHub</a> | 
ğŸ› <a href="https://github.com/simonpierreboucher0/WEB-EXTRACTION/issues">Signaler un problÃ¨me</a> | 
ğŸ’¡ <a href="https://github.com/simonpierreboucher0/WEB-EXTRACTION/discussions">Discussions</a>
</p>
